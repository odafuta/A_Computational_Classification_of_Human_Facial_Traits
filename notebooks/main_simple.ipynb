{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set matplotlib parameters\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: データ読み込み関数の定義\n",
    " - 動物と人間の顔画像を読み込むための2つの関数が定義されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined!\n"
     ]
    }
   ],
   "source": [
    "def load_animal_data(data_dir=\"../data/af_data_new\"):\n",
    "    \"\"\"Load animal image data (3 classes: cat, dog, wild)\"\"\"\n",
    "    print(\"=== Data Collection and Preprocessing ===\")\n",
    "    print(f\"Data source: {data_dir}\")\n",
    "    print(\"Preprocessing: RGB→Grayscale conversion, 128×128 resize, normalization (0-1)\")\n",
    "    \n",
    "    data_path = Path(data_dir)\n",
    "    animal_classes = ['cat', 'dog', 'wild']\n",
    "    X, y = [], []\n",
    "    \n",
    "    for class_idx, class_name in enumerate(animal_classes):\n",
    "        class_dir = data_path / class_name\n",
    "        if not class_dir.exists():\n",
    "            continue\n",
    "            \n",
    "        image_files = list(class_dir.glob(\"*.jpg\")) + list(class_dir.glob(\"*.png\"))\n",
    "        print(f\"{class_name}: {len(image_files)} images\")\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            try:\n",
    "                img = cv2.imread(str(img_path))\n",
    "                if img is None:\n",
    "                    continue\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (128, 128))\n",
    "                img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "                img_normalized = img_gray.flatten() / 255.0\n",
    "                X.append(img_normalized)\n",
    "                y.append(class_idx)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    print(f\"Total data count: {len(X)} images\")\n",
    "    return np.array(X), np.array(y), animal_classes\n",
    "\n",
    "def load_human_data(data_dir=\"../data/af_data_new\"):\n",
    "    \"\"\"Load human image data (animal-like features)\"\"\"\n",
    "    print(\"\\n=== Animal-like Human Face Images ===\")\n",
    "    print(\"Collection method: AI image generation services\")\n",
    "    print(\"Labeling method: Filename-based (e.g., cat_human_01.jpg)\")\n",
    "    \n",
    "    data_path = Path(data_dir) / \"human_like_animal\"\n",
    "    if not data_path.exists():\n",
    "        return np.array([]), np.array([]), []\n",
    "    \n",
    "    X_human, y_human, human_files = [], [], []\n",
    "    class_mapping = {'cat': 0, 'dog': 1, 'wild': 2}\n",
    "    \n",
    "    image_files = list(data_path.glob(\"*.jpg\")) + list(data_path.glob(\"*.png\"))\n",
    "    print(f\"Human image count: {len(image_files)}\")\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        try:\n",
    "            filename = img_path.name\n",
    "            animal_name = filename.split('_')[0].lower()\n",
    "            if animal_name not in class_mapping:\n",
    "                continue\n",
    "            \n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            img_normalized = img_gray.flatten() / 255.0\n",
    "            \n",
    "            X_human.append(img_normalized)\n",
    "            y_human.append(class_mapping[animal_name])\n",
    "            human_files.append(filename)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    for class_name in ['cat', 'dog', 'wild']:\n",
    "        count = sum(1 for f in human_files if f.startswith(class_name))\n",
    "        print(f\"{class_name}-like: {count} images\")\n",
    "    \n",
    "    return np.array(X_human), np.array(y_human), human_files\n",
    "\n",
    "print(\"Data loading functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: データセットの読み込み\n",
    "- 定義した関数を使って、実際に画像データを読み込む。各クラスの画像数や、データの形状（次元数）が出力される。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load animal data\n",
    "X, y, class_names = load_animal_data()\n",
    "print(f\"\\nLoaded data shape: {X.shape}\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Load human data\n",
    "X_human, y_human, human_files = load_human_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: PCA（主成分分析）の実行\n",
    "16,384次元の画像データを、110次元まで圧縮します。これにより、本質的な特徴を保ちながら計算コストを大幅に削減できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA implementation\n",
    "print(\"=== PCA Implementation ===\")\n",
    "print(\"Library used: scikit-learn PCA\")\n",
    "print(\"Hyperparameter: n_components (number of principal components)\")\n",
    "\n",
    "n_components = 110\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_.sum()\n",
    "print(f\"Number of components: {n_components}\")\n",
    "print(f\"Explained variance ratio: {explained_variance:.4f}\")\n",
    "print(f\"Eigenvalues (top 5): {pca.explained_variance_[:5]}\")\n",
    "print(f\"PCA transformed data shape: {X_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: 固有顔の可視化\n",
    "- 主成分は、いわば「平均的な顔」からの差分を表すパターンです。これを画像として表示することで、モデルが顔のどの部分（目、鼻、輪郭など）に注目しているのかを視覚的に理解できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenfaces visualization\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(min(6, n_components)):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    eigenface = pca.components_[i].reshape(128, 128)\n",
    "    plt.imshow(eigenface, cmap='gray')\n",
    "    plt.title(f'Eigenface {i+1}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('PCA Eigenfaces (Top 6 Components)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: PCAによる2次元可視化\n",
    "- 次に、110次元に圧縮したデータをさらに2次元（第一主成分と第二主成分）まで落とし込み、各クラス（cat, dog, wild）がどのように分布しているかを散布図で確認します。これにより、クラスがどの程度分離可能か、視覚的な手がかりを得られます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['red', 'green', 'blue']\n",
    "for i, class_name in enumerate(class_names):\n",
    "    mask = y == i\n",
    "    plt.scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
    "               c=colors[i], label=class_name, alpha=0.6, s=50)\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.title('PCA 2D Visualization (Animal Images)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: 訓練データとテストデータの分割\n",
    "- 次に、機械学習モデルの性能を正しく評価するため、データを「訓練用（80%）」と「テスト用（20%）」に分割します。モデルは訓練用データのみを見て学習し、テスト用データは学習後の性能評価にのみ使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training data: {X_train.shape[0]} samples\")\n",
    "print(f\"Test data: {X_test.shape[0]} samples\")\n",
    "print(f\"Training/Test split: {X_train.shape[0]/(X_train.shape[0]+X_test.shape[0]):.1%}/{X_test.shape[0]/(X_train.shape[0]+X_test.shape[0]):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: SVMの訓練とグリッドサーチ\n",
    "- ここでは、以下の処理を行います。\n",
    "- 特徴量の標準化: 各特徴量（主成分）のスケールを揃え、モデルの学習を安定させます。\n",
    "- グリッドサーチ: SVMの性能を最大化するため、最適なハイパーパラメータ（C, gamma, kernel）の組み合わせを自動的に探索します。\n",
    "- モデルの訓練: 最適なパラメータを使って、SVMモデルを訓練データに適合させます。\n",
    "- この処理は計算に少し時間がかかる場合があります（数分程度）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM implementation\n",
    "print(\"=== SVM Implementation ===\")\n",
    "print(\"Library used: scikit-learn SVC\")\n",
    "print(\"Hyperparameters: C (regularization), gamma (RBF kernel), kernel (kernel function)\")\n",
    "\n",
    "# Feature standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Grid search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "print(\"Running grid search...\")\n",
    "svm = SVC(probability=True) # probability=True is needed for confidence scores later\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Final model\n",
    "svm_model = grid_search.best_estimator_\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nSVM model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: 動物画像の分類性能評価\n",
    "- それでは、訓練したモデルが未知のデータ（テストデータ）に対してどれくらいの性能を発揮するかを評価します。ここでは、以下の2つの指標を使います。\n",
    "- 分類レポート: クラスごとの適合率（Precision）、再現率（Recall）、F1スコアといった詳細な性能指標と、全体の正解率（Accuracy）を表示します。\n",
    "- 混同行列: モデルがどのクラスをどのクラスと間違えやすいかを視覚的に示した行列です。対角線上の数字が大きいほど、正しく分類できていることを意味します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: Animal classification accuracy\n",
    "print(\"=== Experiment 1: Animal Classification Accuracy ===\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Overall accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix - Animal Classification')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: SVMの決定境界の可視化\n",
    "- 次に、SVMがどのようにして3つのクラスを分類しているのか、その「境界線（決定境界）」を可視化します。これにより、モデルの分類ロジックを直感的に理解することができます。\n",
    "- 背景色: モデルが予測するクラス領域を表します。（例: 赤い領域にプロットされた点は「cat」と予測される）\n",
    "点: 実際のデータ点です。\n",
    "- この可視化のために、再度2次元のPCAを行いますが、これはあくまで可視化用であり、実際のモデル（110次元）の性能とは異なります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM decision boundary visualization\n",
    "print(\"=== SVM Decision Boundary Visualization ===\")\n",
    "\n",
    "# 2D PCA for visualization\n",
    "pca_2d = PCA(n_components=2)\n",
    "X_2d = pca_2d.fit_transform(X)\n",
    "\n",
    "# Standardization\n",
    "scaler_2d = StandardScaler()\n",
    "X_2d_scaled = scaler_2d.fit_transform(X_2d)\n",
    "\n",
    "# SVM training for 2D\n",
    "svm_vis = SVC(kernel='rbf', C=10, gamma='scale')\n",
    "svm_vis.fit(X_2d_scaled, y)\n",
    "\n",
    "# Create mesh\n",
    "margin = 0.5\n",
    "x_min, x_max = X_2d_scaled[:, 0].min() - margin, X_2d_scaled[:, 0].max() + margin\n",
    "y_min, y_max = X_2d_scaled[:, 1].min() - margin, X_2d_scaled[:, 1].max() + margin\n",
    "\n",
    "h = 0.02\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                    np.arange(y_min, y_max, h))\n",
    "\n",
    "Z = svm_vis.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\n",
    "\n",
    "colors = ['red', 'green', 'blue']\n",
    "for i in range(len(class_names)):\n",
    "    mask = y == i\n",
    "    plt.scatter(X_2d_scaled[mask, 0], X_2d_scaled[mask, 1],\n",
    "               c=colors[i], label=class_names[i], edgecolor='k', alpha=0.8)\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xlabel('First Principal Component (Scaled)')\n",
    "plt.ylabel('Second Principal Component (Scaled)')\n",
    "plt.title('SVM Decision Boundary (2D PCA Space)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: 人間画像の分類と評価\n",
    "- いよいよ最終段階です。動物の顔で訓練したモデルが、動物的な特徴を持つ人間の顔をどのように分類するかを検証します。\n",
    "- 前処理の適用: 人間画像にも、動物画像と全く同じPCAと標準化を適用します。\n",
    "- 予測と確信度の計算: svm_model を使って、各人間画像を予測し、その際の「確信度（probability）」も計算します。\n",
    "- 結果の表示: ファイル名、予測結果、正解、そしてモデルがどれくらいその予測に自信があるか（確信度）を一覧で表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Human image classification\n",
    "if len(X_human) > 0:\n",
    "    print(\"=== Experiment 2: Human Image Classification Results ===\")\n",
    "    \n",
    "    # Apply same preprocessing pipeline\n",
    "    X_human_pca = pca.transform(X_human)\n",
    "    X_human_scaled = scaler.transform(X_human_pca)\n",
    "    \n",
    "    # Prediction\n",
    "    predictions = svm_model.predict(X_human_scaled)\n",
    "    probabilities = svm_model.predict_proba(X_human_scaled)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Classification results:\")\n",
    "    results = []\n",
    "    for i, (filename, pred) in enumerate(zip(human_files, predictions)):\n",
    "        ground_truth = class_names[y_human[i]]\n",
    "        predicted = class_names[pred]\n",
    "        confidence = probabilities[i][pred]\n",
    "        correct = \"✓\" if pred == y_human[i] else \"✗\"\n",
    "        print(f\"{filename}: {predicted} (Confidence: {confidence:.2%}) | Ground truth: {ground_truth} {correct}\")\n",
    "        \n",
    "        results.append({\n",
    "            'filename': filename,\n",
    "            'predicted': predicted,\n",
    "            'ground_truth': ground_truth,\n",
    "            'correct': pred == y_human[i]\n",
    "        })\n",
    "    \n",
    "    # Accuracy evaluation\n",
    "    human_accuracy = accuracy_score(y_human, predictions)\n",
    "    print(f\"\\nHuman image classification accuracy: {human_accuracy:.4f} ({human_accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_human, predictions, target_names=class_names))\n",
    "else:\n",
    "    print(\"No human images found for evaluation\")\n",
    "    results = []\n",
    "    human_accuracy = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12: 人間画像の分類結果の可視化\n",
    "- 最後に、人間画像の分類結果を2つのグラフで可視化して、傾向を詳しく分析します。\n",
    "- 混同行列: 人間画像において、どのクラスがどのクラスに間違われやすいかを表示します。\n",
    "- 分類結果の棒グラフ: 全体として、どの動物の特徴（cat, dog, wild）に分類される傾向が強いかを示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X_human) > 0:\n",
    "    # Confusion matrix for human classification\n",
    "    cm_human = confusion_matrix(y_human, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_human, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix - Human Image Classification')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification results summary\n",
    "    class_counts = {'cat': 0, 'dog': 0, 'wild': 0}\n",
    "    for result in results:\n",
    "        class_counts[result['predicted']] += 1\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(class_counts.keys(), class_counts.values(), color=['red', 'green', 'blue'])\n",
    "    plt.title('Human Image Classification Results')\n",
    "    plt.xlabel('Animal Class')\n",
    "    plt.ylabel('Number of Images')\n",
    "    for bar, count in zip(bars, class_counts.values()):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., bar.get_height(),\n",
    "                f'{count}', ha='center', va='bottom')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No human images to visualize\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
